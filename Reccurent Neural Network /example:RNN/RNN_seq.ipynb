{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch import nn \n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# cuda\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>I love this film. It's one of those I can watc...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40345</th>\n",
       "      <td>If you are a bit masochistic and like to waste...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>The Ballad of Django is a meandering mess of a...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28149</th>\n",
       "      <td>Story about a widowed father (Claude Rains) br...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14762</th>\n",
       "      <td>I saw this very emotionally painful portrayal ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12789</th>\n",
       "      <td>This movie was extremely boring. It should lea...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30486</th>\n",
       "      <td>The Matador is better upon reflection because ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18739</th>\n",
       "      <td>Oddly, I have very little to say about \"The Bo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20832</th>\n",
       "      <td>Lillian Hellman, one of America's most famous ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21729</th>\n",
       "      <td>This movie was poorly written, poorly acted an...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "4756   I love this film. It's one of those I can watc...  positive\n",
       "40345  If you are a bit masochistic and like to waste...  negative\n",
       "4402   The Ballad of Django is a meandering mess of a...  negative\n",
       "28149  Story about a widowed father (Claude Rains) br...  positive\n",
       "14762  I saw this very emotionally painful portrayal ...  positive\n",
       "12789  This movie was extremely boring. It should lea...  negative\n",
       "30486  The Matador is better upon reflection because ...  positive\n",
       "18739  Oddly, I have very little to say about \"The Bo...  negative\n",
       "20832  Lillian Hellman, one of America's most famous ...  positive\n",
       "21729  This movie was poorly written, poorly acted an...  negative"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/home/veinmahzy/Implement Deep Learning Paper/Reccurent Neural Network /example:RNN/IMDB Dataset.csv\")\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\"\n",
      " 'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'\n",
      " 'I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I\\'d laughed at one of Woody\\'s comedies in years (dare I say a decade?). While I\\'ve never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.'\n",
      " ...\n",
      " 'I am a Catholic taught in parochial elementary schools by nuns, taught by Jesuit priests in high school & college. I am still a practicing Catholic but would not be considered a \"good Catholic\" in the church\\'s eyes because I don\\'t believe certain things or act certain ways just because the church tells me to.<br /><br />So back to the movie...its bad because two people are killed by this nun who is supposed to be a satire as the embodiment of a female religious figurehead. There is no comedy in that and the satire is not done well by the over acting of Diane Keaton. I never saw the play but if it was very different from this movies then it may be good.<br /><br />At first I thought the gun might be a fake and the first shooting all a plan by the female lead of the four former students as an attempt to demonstrate Sister Mary\\'s emotional and intellectual bigotry of faith. But it turns out the bullets were real and the story has tragedy...the tragedy of loss of life (besides the two former students...the lives of the aborted babies, the life of the student\\'s mom), the tragedy of dogmatic authority over love of people, the tragedy of organized religion replacing true faith in God. This is what is wrong with today\\'s Islam, and yesterday\\'s Judaism and Christianity.'\n",
      " 'I\\'m going to have to disagree with the previous comment and side with Maltin on this one. This is a second rate, excessively vicious Western that creaks and groans trying to put across its central theme of the Wild West being tamed and kicked aside by the steady march of time. It would like to be in the tradition of \"Butch Cassidy and the Sundance Kid\", but lacks that film\\'s poignancy and charm. Andrew McLaglen\\'s direction is limp, and the final 30 minutes or so are a real botch, with some incomprehensible strategy on the part of heroes Charlton Heston and Chris Mitchum. (Someone give me a holler if you can explain to me why they set that hillside on fire.) There was something callous about the whole treatment of the rape scene, and the woman\\'s reaction afterwards certainly did not ring true. Coburn is plenty nasty as the half breed escaped convict out for revenge, but all of his fellow escapees are underdeveloped (they\\'re like bowling pins to be knocked down one by one as the story lurches forward). Michael Parks gives one of his typically shifty, lethargic, mumbling performances, but in this case it was appropriate as his modern style sheriff symbolizes the complacency that technological progress can bring about.'\n",
      " \"No one expects the Star Trek movies to be high art, but the fans do expect a movie that is as good as some of the best episodes. Unfortunately, this movie had a muddled, implausible plot that just left me cringing - this is by far the worst of the nine (so far) movies. Even the chance to watch the well known characters interact in another movie can't save this movie - including the goofy scenes with Kirk, Spock and McCoy at Yosemite.<br /><br />I would say this movie is not worth a rental, and hardly worth watching, however for the True Fan who needs to see all the movies, renting this movie is about the only way you'll see it - even the cable channels avoid this movie.\"]\n",
      "['positive' 'positive' 'positive' ... 'negative' 'negative' 'negative']\n"
     ]
    }
   ],
   "source": [
    "X,y = data['review'].values,data['sentiment'].values\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 40000, 10000, 10000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split = int (0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:],y[train_split:]\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocess_string(s):\n",
    "    s = re.sub(r\"[^\\w\\s]\", '', s)  # Hapus karakter non-kata kecuali spasi\n",
    "    s = re.sub(r\"\\s+\", '', s)  # Hapus spasi berlebih\n",
    "    s = re.sub(r\"\\d\", '', s)  # Hapus angka\n",
    "    return s\n",
    "\n",
    "def build_onehot_dict(x_train, vocab_size=1000):\n",
    "    word_list = []\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    \n",
    "    for sent in x_train:\n",
    "        for word in sent.lower().split():\n",
    "            word = preprocess_string(word)\n",
    "            if word not in stop_words and word:\n",
    "                word_list.append(word)\n",
    "    \n",
    "    corpus = Counter(word_list)\n",
    "    common_words = sorted(corpus, key=corpus.get, reverse=True)[:vocab_size]\n",
    "    onehot_dict = {w: i + 1 for i, w in enumerate(common_words)}\n",
    "    \n",
    "    return onehot_dict\n",
    "\n",
    "def tokenize_sentences(sentences, onehot_dict):\n",
    "\n",
    "    tokenized_sentences = []\n",
    "    for sent in sentences:\n",
    "        tokenized_sentences.append([\n",
    "            onehot_dict[preprocess_string(word)] \n",
    "            for word in sent.lower().split() \n",
    "            if preprocess_string(word) in onehot_dict\n",
    "        ])\n",
    "    return np.array(tokenized_sentences, dtype=object)\n",
    "\n",
    "def encode_labels(labels):\n",
    "    return np.array([1 if label == 'positive' else 0 for label in labels])\n",
    "\n",
    "def tokenize(x_train, y_train, x_val, y_val, vocab_size=1000):\n",
    "   \n",
    "    onehot_dict = build_onehot_dict(x_train, vocab_size)\n",
    "    x_train_tokens = tokenize_sentences(x_train, onehot_dict)\n",
    "    x_val_tokens = tokenize_sentences(x_val, onehot_dict)\n",
    "    y_train_encoded = encode_labels(y_train)\n",
    "    y_val_encoded = encode_labels(y_val)\n",
    "    \n",
    "    return x_train_tokens, y_train_encoded, x_val_tokens, y_val_encoded, onehot_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test,vocab = tokenize( X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([4, 941, 57, 299, 335, 105, 472, 479, 1, 20, 58, 51, 462, 180, 105, 559, 53, 42, 42, 276, 462, 248, 234, 1, 361, 235, 958, 413, 295, 213, 413, 237, 220, 34, 131, 1, 8, 47, 170, 42, 546, 93, 163, 157, 442, 698, 85, 956, 698, 698, 60, 869, 89, 20, 299, 43, 107, 292, 47, 177, 91, 213, 462, 462, 383, 503, 15, 141, 14, 646, 686, 541, 546, 433, 790, 440, 57, 101, 309, 15, 390])\n",
      " list([274, 39, 250, 1, 1, 288, 401, 178, 316, 296, 1, 1, 59, 430, 14, 386, 91, 244, 11, 678, 14, 165, 57, 322, 296, 250, 4, 16, 113, 44, 1, 1, 10, 160, 237, 39, 84, 961, 142, 234, 893, 188, 446, 51, 593, 446, 964, 73, 14, 126])\n",
      " list([100, 274, 27, 959, 9, 774, 822, 631, 57, 113, 38, 298, 28, 7, 14, 382, 101, 570, 812, 919, 124, 100, 46, 323, 31, 77, 1, 340, 4, 62, 47, 96, 34, 105, 719, 90, 1, 101, 539, 115, 16, 113, 53, 11, 225])\n",
      " ...\n",
      " list([42, 36, 59, 16, 12, 300, 28, 285, 364, 471, 16, 298, 10, 577, 709, 334, 16, 471, 16, 483, 188, 14, 373, 268, 205, 892, 42, 10, 431, 4, 385, 672, 42, 434, 734, 72, 765, 403, 42, 67, 291, 594, 157, 315, 42, 10, 103, 9, 19, 41, 6, 34, 83, 42, 49, 43])\n",
      " list([93, 2, 985, 2, 3, 372, 67, 311, 187, 9, 389, 26, 6, 634, 1, 12, 784, 115, 333, 386, 106, 747, 36, 1, 37, 27, 60, 10, 263, 491, 188, 122, 451, 148, 142, 518, 1, 1, 639, 113, 770, 74, 703, 65, 576, 242, 530, 363, 119, 2, 65, 229, 313, 113, 354, 725, 427, 1, 484, 484, 83, 113, 24, 146, 143, 7, 21, 399, 1, 419, 97, 302, 82, 65, 183, 9, 429, 75, 183, 9, 63])\n",
      " list([1, 207, 27, 207, 176, 177, 174, 928, 563, 100, 444, 13, 5, 221, 173, 1, 365, 379, 3, 243, 1, 577, 8, 34, 397, 5, 174, 35, 174, 126, 695, 117, 173, 695, 1, 154, 525, 173, 928, 272, 41, 173, 143, 66, 525, 78, 173, 246, 872, 215, 1, 154, 207, 13, 4, 633, 5, 161, 39, 352, 457, 28, 42, 525, 51, 26, 735, 339, 51, 27, 131, 1, 36, 21, 327, 9])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "def padding_(sentences, seq_len):\n",
    "    \n",
    "    features = np.zeros((len(sentences), seq_len), dtype=int)\n",
    "    for ii, review in enumerate(sentences):\n",
    "        if len(review) != 0:\n",
    "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
    "    return features\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "def create_dataloaders(x_train, y_train, x_val, y_val, seq_len=500, batch_size=50):\n",
    "    \"\"\"\n",
    "    Make data loader for validation and train\n",
    "    \"\"\"\n",
    "    x_train_pad = padding_(x_train, seq_len)\n",
    "    x_val_pad = padding_(x_val, seq_len)\n",
    "    \n",
    "    train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\n",
    "    valid_data = TensorDataset(torch.from_numpy(x_val_pad), torch.from_numpy(y_val))\n",
    "    \n",
    "    train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "    valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    return train_loader, valid_loader\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
